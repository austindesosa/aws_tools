# -*- coding: utf-8 -*-
"""aws_local.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZWGzQ27MO2BSMKgVHnnwRqomSoIibbGs

This file is meant to use boto3 to connect with AWS resources on a local machine (as opposed to google colab).
"""

import os

INSTALL_BOTO = False #boolean whether you need to pip install boto3
#True if you need to install it, False if boto3 ois already pip installed
if INSTALL_BOTO:
  os.system('pip install boto3') 

WINDOWS_COMPAT = False #boolean whether you want to change Numpy version
#to be Windows compatible

if WINDOWS_COMPAT:
  os.system('pip uninstall numpy')
  os.system('pip install numpy==1.19.3')

import numpy as np
import pandas as pd


import json
import glob
from datetime import datetime
from time import time
import boto3



MAKE_REQS = False #Boolean telling whether you should make a requirements.txt file
REQS_NAME = 'aws_requirements.txt' #name of file containing requirements
if MAKE_REQS:
  os.system(f'pip freeze > {REQS_NAME}')

def shell_cmd(fname):
  '''fname : string, filename of .txt file in this directory
  Executes the shell commands in fname
  returns int, exit code for os.system'''
  x = None
  with open(fname) as f:
    x = f.read()
  return os.system(x)


REGION = 'us-west-2'

def iam_credentials(csv_name = 'new_user_credentials.csv', dxry=None):
  '''Gets IAM credentials from a CSV file as provided by AWS for that purpose,
  returns tuple containing (username, dictionary of credentials)
  csv_name : string, name of CSV file
  dxry : Dictionary or NoneType, optional dictionary to add return value to
  Returns
  key : string, name of IAM user, 
  val : dictionary, contains access key ID and secret access key for that IAM user
  Also adds key-value pair (key, val) to dictionary dxry'''
  daf = pd.read_csv(csv_name)
  key = daf['User name'][0]
  val = {}
  val['access_key_id'] = daf['Access key ID'][0]
  val['secret_access_key'] = daf['Secret access key'][0]
  if dxry:
    dxry[key]=val
  return key, val

def quick_iam_dxry(json_file = 'aws_accounts.json', 
                   acct_name = 'austin_poyz',
                   key_name = 'iam_users'):
  '''Returns dictionary of IAM user credentials stored in a JSON file
  json_file : string, name of JSON file in your directory containing the needed information
  acct_name : string, name of AWS account to which IAM users belong
  key_name : string, dictionary key whose value is a dictionary containing IAM users and their credentials
  This returns a dictionary containimg the credentials for all the IAM users associated with an AWs account
  '''
  ret = json.load(open(json_file))[acct_name][key_name]
  return ret

def iam_from_creds(iam_name, aki, sak):
  '''Returns nested dictionary containing one set of IAM credentials
  iam_name : string, name of IAM user
  aki : string, Access key ID for that IAM user
  sak : string, Secret access key for that IAM user
  Returns dictionary of form similar to the one stored in JSON credential file
  This is for when you just have the IAM user name, the access key ID, and the secret access key
  '''
  d = {'access_key_id':aki, 'secret_access_key': sak}
  return {iam_name : d}

def update_json(dxry,
                bucket, 
                your_fname='aws_accounts.json', 
                aws_fname='aws_accounts.json'):
  '''Updates the contents of a JSON file and uploads it to an S3 bucket
  dxry : dictionary, represents new contents of the JSON file
  bucket : boto3.resources.factory.s3.Bucket object representing S3 bucket to upload to
  your_fname : string, filename of JSON file in your present directory
  aws_fname : string, name you want the file to have in your s3 bucket
  Returns None
  '''
  with open(your_fname, 'w') as f:
    f.write(json.dumps(dxry))
  bucket.upload_file(your_fname, aws_fname)

def upload_to_dataset(df, 
                     your_fname, 
                     aws_fname, 
                     bucket,
                     y_label = 0, 
                     key_str='filename',
                     value_str='y_label'
                     ):
  '''Uploads file to bucket, gives it a label for machine learning,
  logs that information to a pandas.DataFrame
  df : pandas.DataFrame, to store the information along with info about other file-label pairs
  your_fname : string, name of file in your directory
  aws_fname : string, name of file it will have in bucket,
  y_label : int, category of image uploaded for neural network purposes
  bucket : boto3.resources.factory.s3.Bucket object for bucket to upload to
  key_name : string, column label storing filenames
  value_name : string, column label containing machine learning labels
  Returns dictionary whose values are the filename and the machine learning label'''
  bucket.upload_file(your_fname, aws_fname)
  dx = {key_str : aws_fname,
       value_str : y_label,
       }
  df.append(dx)
  return dx

def service(service_name, iam_name, iam_dxry, region='us-west-2', func = boto3.resource):
  '''Returns an object mean to access an AWS service, as returned by boto3.resource or  boto3.client methods
  service_name : string, name of desired AWS service
  iam_name : string, name of IAM user whose credentials will be used to access the service,
  iam_dxry : dictionary, keys are IAM usernames and values are dictionaries containing IAM credentials,
  region : string , name of AWS region hosting the service,
  func : boto3.resource | boto3.client, Python function to connect to the service
  Returns object of the same type as returned by func
  '''
  creds = iam_dxry[iam_name]
  aki, sak = creds['access_key_id'], creds['secret_access_key']
  ret = func(service_name, 
             region_name = region,
             aws_access_key_id = aki,
             aws_secret_access_key = sak)
  return ret

def s3_and_bucket(bucket_name = 'pythonbucket6071',
                  iam_dxry_name = 'iam_users',
                  s3_name = 's3iam',
                  json_name = 'aws_accounts.json',
                  acct_name = 'austin_poyz'):
  '''Returns tuple containing (ServiceResource , Bucket) objects 
  from s3.resource.factory.s3 library.
  bucket_name : string, name of s3 bucket you want to access with your Bucket object
  iam_dxry_name : string, name of inner dictionary containing IAM user info
  s3_name : string, name of IAM user with progtrammatic access to that S3 bucket
  json_name : name of JSON file containing AWS account info including IAM users
  acct_name : AWS account associated with your IAM user, as listed in the JSON file
  '''
  acct_dxry = json.load(open(json_name))
  iam_dxry = acct_dxry[acct_name][iam_dxry_name]
  s3 = service('s3', 
               iam_name = s3_name,
               iam_dxry = iam_dxry,
               func = boto3.resource)
  bucket  = s3.Bucket(bucket_name)
  return s3, bucket

def process_iam(csv_name = 'new_user_credentials.csv',
                json_name = 'aws_accounts.json',
                aws_json_name = 'secrets/aws_accounts.json',
                iam_dxry_name = 'iam_users',
                acct_name = 'austin_poyz',
                s3_name = 's3iam', 
                bucket_name = 'pythonbucket6071',
                s3_service = None,
                return_objects = True
                ):
  '''csv_name : string, name of .csv file provided by AWS containing IAM user credentials
  json_name : string, name of .json file in this directory containing information about your accounts
              and ytheir IAM users
  aws_json_name : name of the JSON file with account information as known in your S3 bucket
  iam_dxry_name : string, key whose value is dictionary of all IAM users for an AWS account
                  in the dictionary form of json_name
  acct_name : string, name of AWS account associated with your IAM user
  s3_name : string, name of IAM user with S3 permission mentioned in json_name
  bucket_name : string, name of S3 bucket where you will keep JSON file
  s3_service : boto3.resource('s3') object or None, object to connect with S3
  return_objects : boolean, whether or not to return a tuple of objects
  If return_objects is True, returns tuple containing 
  ( boto3.resources.factory.s3 , boto3.resources.factory.s3.Bucket ) datatypes
  Otherwise returns None
  '''
  cred_key, cred_val = iam_credentials(csv_name)
  acct_dxry = json.load(open(json_name))
  iam_dxry = acct_dxry[acct_name][iam_dxry_name]
  iam_dxry[cred_key] = cred_val
  if (not s3_service):
    s3_service = service('s3', 
                         iam_name = s3_name, 
                         iam_dxry = iam_dxry, 
                         func = boto3.resource)
  bucket = s3_service.Bucket(bucket_name)
  update_json(dxry = acct_dxry,
              bucket = bucket,
              your_fname = json_name,
              aws_fname = aws_json_name)
  ret = None
  if return_objects:
    ret = (s3_service , bucket)
  return ret

def make_ni_dxry(subnet, sg, device_index = 0, public_ip = True):
  ret = {}
  ret['SubnetId'] = subnet.id   
  ret['DeviceIndex']=device_index   
  ret['AssociatePublicIpAddress']=public_ip   
  ret['Groups']=[sg.group_id]
  return ret

def basic_vpc_launch(vpc_cidr = '172.16.0.0/16',
               vpc_name = 'my_vpc',
               subnet_cidr = '172.16.1.0/24',
               sg_groupname = 'SSH-ONLY',
               sg_description = 'Only allow SSH traffic',
               ip_protocol = 'tcp',
               ingress_cidr = '0.0.0.0/0',
               from_port = 22,
               to_port = 22,
               min_count = 1, 
               max_count = 1,
               region = 'us-west-2',
               bootstrap_file = 'setup_script.txt',
               ec2_json = 'aws_ec2.json',
               device_index = 0,
               public_ip = True,
               ec2_service = None,
               ec2_iam_name = 'ec2iam',
               iam_dxry_name = 'iam_users',
               acct_name = 'austin_poyz',
               json_name = 'aws_accounts.json',
               key_name = 'key0123'):
  ret = {}
  iam_dxry = quick_iam_dxry(json_name, acct_name, iam_dxry_name)
  if not ec2_service:
    ec2_service = service('ec2',
                          iam_name = 'ec2iam', 
                          iam_dxry = iam_dxry,
                          func = boto3.resource
                          )
  ret['ec2_service'], ret['ec2_client']=ec2_service, ec2_service.meta.client 
  vpc = ec2_service.create_vpc(CidrBlock = vpc_cidr)
  vpc.wait_until_available()
  ret['vpc']=vpc
  tag = {'Key':'Name', 'Value' : vpc_name}
  vpc.create_tags(Tags = [tag])
  vpc.wait_until_available()
  internetgateway = ec2_service.create_internet_gateway()
  vpc.attach_internet_gateway(InternetGatewayId = internetgateway.id)
  ret['internet_gateway'] = internetgateway
  print(f'internetgateway.id = {internetgateway.id} \n')
  routetable = vpc.create_route_table()
  ret['route_table'] = routetable
  try:
    route = routetable.create_route(DestinationCidrBlock = '0.0.0.0/0',
                           GatewayId = internetgateway.id)
  except:
    print('Launch failed \n')
    ret['ec2_client'].delete_vpc(VpcId = vpc.id)
    print('VPC deleted, sorry \n')
    return ret
  ret['route'] = route
  subnet = ec2_service.create_subnet(CidrBlock = subnet_cidr,
                             VpcId = vpc.id)
  ret['subnet'] = subnet
  routetable.associate_with_subnet(SubnetId = subnet.id)
  securitygroup = ec2_service.create_security_group(GroupName = sg_groupname,
                                            Description = sg_description,
                                            VpcId = vpc.id)
  securitygroup.authorize_ingress(CidrIp = ingress_cidr,
                                  IpProtocol = ip_protocol,
                                  FromPort = from_port,
                                  ToPort = to_port)
  ret['security_group'] = securitygroup 
  ni_dxry = make_ni_dxry(subnet=subnet, 
                         sg = securitygroup,
                         device_index = device_index,
                         public_ip = public_ip)
  user_data = None
  if bootstrap_file:
    user_data = open(bootstrap_file).read()
  ec2_d = json.load(open(ec2_json))
  instances = ec2_service.create_instances(ImageId = ec2_d['ImageId'],
                    InstanceType = ec2_d['InstanceType'],
                    MaxCount=1,
                    MinCount=1,
                    NetworkInterfaces = [ni_dxry],
                    UserData = user_data,
                    KeyName = 'key0123')
  return ret

  